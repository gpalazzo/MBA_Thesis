{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_kedro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score, classification_report, roc_curve\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from numpy import array #useful to parse values\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMGS_PATH = \"/Users/gpalazzo/Desktop/dev/mba_Otavio/assets/images\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = catalog.load(\"logreg_fitted_model\")\n",
    "\n",
    "X_test = catalog.load(\"master_table_teste_ftes\")\n",
    "y_test = catalog.load(\"master_table_teste_tgt\")\n",
    "y_pred = catalog.load(\"logreg_model_predict\")\n",
    "\n",
    "df_model_rpt = catalog.load(\"logreg_model_relatorio\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_roc_auc_score = roc_auc_score(y_true=y_test, y_score=y_pred)\n",
    "_roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_true=y_test, y_pred=y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(fpr, tpr, label=\"Regressão Logística (área = %0.2f)\" % _roc_auc_score)\n",
    "plt.plot([0, 1], [0, 1], linestyle=\"--\", color=\"gray\")\n",
    "\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"Taxa de Falso Positivo\")\n",
    "plt.ylabel(\"Taxa de Verdadeiro Positivo\")\n",
    "\n",
    "plt.title(\"Curva ROC: Regressão Logística\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "\n",
    "plt.savefig(f\"{IMGS_PATH}/logreg_curva_roc.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = eval(df_model_rpt[\"confusion_matrix\"][0])\n",
    "\n",
    "ax = plt.subplot()\n",
    "plot = sns.heatmap(cm, annot=True, ax=ax)\n",
    "ax.set_xlabel(\"Label de Predição\")\n",
    "ax.set_ylabel(\"Label Real\")\n",
    "ax.set_title(\"Matriz de Confusão: Regressão Logística\")\n",
    "\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(f\"{IMGS_PATH}/logreg_cm.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "probas = eval(df_model_rpt[\"test_probas\"].values[0])\n",
    "\n",
    "probas_df = pd.DataFrame.from_dict(data=probas, orient=\"index\")\n",
    "probas_df = probas_df.sort_index()\n",
    "\n",
    "df = probas_df.merge(y_test, left_index=True, right_index=True, how=\"inner\")\n",
    "assert df.shape[0] == probas_df.shape[0] == y_test.shape[0]\n",
    "df2 = df.merge(y_pred, left_index=True, right_index=True, how=\"inner\")\n",
    "assert df.shape[0] == df2.shape[0]\n",
    "\n",
    "df_right = df2[df2[\"label\"] == df2[\"y_pred\"]]\n",
    "df_wrong = df2.drop(df_right.index)\n",
    "\n",
    "df_right = df_right.drop(columns=[\"label\"])\n",
    "right_probas = df_right[[\"proba_label_0\", \"proba_label_1\"]].max(axis=1)\n",
    "\n",
    "df_wrong = df_wrong.drop(columns=[\"label\"])\n",
    "wrong_probas = df_wrong[[\"proba_label_0\", \"proba_label_1\"]].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = right_probas.hist()\n",
    "\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(f\"{IMGS_PATH}/hist_proba_label_correta.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot = wrong_probas.hist()\n",
    "\n",
    "fig = plot.get_figure()\n",
    "fig.savefig(f\"{IMGS_PATH}/hist_proba_label_errada.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fte_imp = eval(df_model_rpt[\"fte_importance\"][0])[\"importance\"]\n",
    "\n",
    "data = {\"features\": fte_imp.keys(),\n",
    "       \"importance\": fte_imp.values()}\n",
    "\n",
    "df_fte_imp = pd.DataFrame.from_dict(data=data)\n",
    "df_fte_imp = df_fte_imp.sort_values(by=\"importance\", ascending=False)\n",
    "\n",
    "print(df_fte_imp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Kedro (itaete_buy_prop)",
   "language": "python",
   "name": "kedro_itaete_buy_prop"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
